Here is the **Lecture 5 Summary**.

This lecture is very specific about **Risks**, **Prompt Engineering Tactics**, and **LLM Concepts**. These are extremely high-yield topics for "fill-in-the-blank" questions.

***

# üìò Lecture 5: Generative AI for Software Testing

## üéØ Concept Match (Reverse Dictionary)
*Read the description $\to$ Write the Term*

*   A type of AI trained on massive text data to generate human-like language $\to$ **LLM (Large Language Model)**
*   The core function of an LLM (calculating the next probable word) $\to$ **Statistical Prediction**
*   The natural language instruction sent to an AI model $\to$ **Prompt**
*   The specific architecture LLMs use to understand context $\to$ **Transformer**
*   The training process where human behavior guides the model's fine-tuning $\to$ **RLHF (Reinforcement Learning from Human Feedback)**
*   The shift where AI becomes accessible to everyone (not just experts) $\to$ **AI Democratization**
*   The tendency of an LLM to confidently generate false or fabricated information $\to$ **Hallucination**
*   Unintentionally revealing sensitive/private info via prompt inputs $\to$ **Data Leakage**
*   Understanding where training data comes from and its ownership $\to$ **Data Provenance**
*   Psychological shortcuts causing users to overtrust or undertrust AI $\to$ **Cognitive Bias**
*   The practice of designing and refining prompts for accurate outputs $\to$ **Prompt Engineering**
*   Using markers (like `#`, `"""`, `< code >`) to separate instructions from data $\to$ **Delimiters**
*   Providing examples in the prompt to guide the model $\to$ **Few-Shot Prompting**
*   Refining a prompt step-by-step (debugging the prompt) $\to$ **Iterative Prompting**
*   The number of statistical weights in a model (measure of size) $\to$ **Parameter Count**

---

## üìã Classifications & Lists

*   **Three Tenets of Success with LLMs:**
    1.  **Mindset** (Understanding capabilities/limitations).
    2.  **Technique** (Writing clear instructions).
    3.  **Context** (Providing background details).

*   **Common LLM Risks:**
    *   Hallucinations.
    *   Data Provenance & Privacy.
    *   Data Leakage.

*   **Prompt Engineering Principles (Ng & Fulford):**
    *   **Principle 1:** Write clear and specific instructions.
    *   **Principle 2:** Give the model time to "think".

*   **Prompt Engineering Tactics:**
    1.  Use **Delimiters**.
    2.  Ask for **Structured Output** (JSON, Table).
    3.  Check for **Assumptions** (Define edge cases).
    4.  **Few-Shot Prompting** (Give examples).
    5.  Specify **Steps** (Break down tasks).
    6.  Instruct model to **work out solution** first.

---

## üß† Case Study Triggers (Decision Making)
*If the exam gives you a scenario $\to$ Identify the Solution/Concept*

*   **Scenario:** You ask ChatGPT to write a test case, but it references a library method that *does not exist*.
    *   **Problem:** Hallucination
*   **Scenario:** You paste proprietary source code or customer passwords into a public ChatGPT prompt.
    *   **Risk:** Data Leakage
*   **Scenario:** You are testing a registration form. You ask the LLM to create a list of fake names, emails, and addresses.
    *   **Task:** Data Generation
*   **Scenario:** You ask the LLM to write a test script. In the prompt, you include: *"Input: 'Login', Output: 'Success'. Input: 'BadPass', Output: 'Fail'."*
    *   **Technique:** Few-Shot Prompting
*   **Scenario:** Your prompt is long and confusing. The AI output is bad. You rewrite the prompt to use XML tags `<data>` to separate the code.
    *   **Technique:** Using Delimiters
*   **Scenario:** Instead of asking "Test this," you ask: "1. List preconditions. 2. Write positive tests. 3. Write negative tests. 4. Output as JSON."
    *   **Technique:** Specifying Steps (or Structured Output)
*   **Scenario:** You blindly trust the code generated by the AI without reviewing it because "AI is smart."
    *   **Problem:** Automation Bias (or Overtrust/Cognitive Bias)
*   **Scenario:** You need to choose an LLM. You look at how easily it integrates with your existing systems via API.
    *   **Criterion:** Extensibility and Integration

---

## ‚ö†Ô∏è Important Distinctions
*   **Probabilistic vs. Deterministic:** LLMs are **Probabilistic** (guess the next word), NOT Deterministic (fact-based databases).
*   **Zero-Shot vs. Few-Shot:**
    *   *Zero-Shot:* No examples given.
    *   *Few-Shot:* Examples provided in prompt.
*   **Hallucination vs. Error:** Hallucination is *plausible* but *fabricated* (made up facts).
*   **RLHF:** This is the specific method that makes models like ChatGPT "chatty" and helpful (Human Feedback).